{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lbonati@iit.local/software/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlcvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | blocks | Sequential | 86     | [2]      | [1]      \n",
      "-------------------------------------------------------------\n",
      "86        Trainable params\n",
      "0         Non-trainable params\n",
      "86        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "SimpleCV(\n",
      "  (blocks): Sequential(\n",
      "    (0): Normalization()\n",
      "    (1): FeedForward(\n",
      "      (nn): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=5, out_features=10, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=10, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Epoch 1: 100%|██████████| 4/4 [00:00<00:00, 274.14it/s, loss=5.34]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [00:00<00:00, 237.47it/s, loss=5.34]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "from typing import Any\n",
    "\n",
    "from mlcvs.core import FeedForward, Normalization\n",
    "from mlcvs.utils.data import TensorDataModule\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from mlcvs.core.utils.decorators import decorate_methods,call_submodules_hooks,allowed_hooks\n",
    "\n",
    "@decorate_methods(call_submodules_hooks,methods=allowed_hooks)\n",
    "class SimpleCV(pl.LightningModule):\n",
    "    \"\"\"Example of collective variable obtained with a regression task.\n",
    "    Initalize the architecture as a torch.nn.sequential model and the \n",
    "    loss function (MSE) in the training_step function. \"\"\"\n",
    "    \n",
    "    def __init__(self, options : dict[str, Any] = None , modules : list = None, **kwargs):\n",
    "        \"\"\"Initialize the CV either from a dictionary or with a list of pl.LightningModules for greater flexibility. \n",
    "\n",
    "        If instead a list of modules is given they will supersede the options dict.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        options : dict[str, Any], optional\n",
    "            The allowed keys are :\n",
    "            - layers  :  list of nodes per layers (e.g. [n_input, n_hidden, n_output]).\n",
    "            - activation : type of activation function (see FeedForward class) \n",
    "            - normIn  : how to normalize inputs (std,minmax,False/None), default std\n",
    "        modules : list of pl.LightningModules, alternative\n",
    "            list of modules, by default None\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if ( modules is not None ):\n",
    "            self.blocks = torch.nn.Sequential(*modules)\n",
    "        else:\n",
    "            # parse layers\n",
    "            try:\n",
    "                layers = options['layers']\n",
    "            except KeyError:\n",
    "                raise KeyError('the key layers (e.g. [n_input, n_hidden, n_output]) is missing in the options dict')\n",
    "            n_in = layers[0] \n",
    "            # parse activation\n",
    "            activation = options['activation'] if 'activation' in options else 'relu'\n",
    "            # create NN\n",
    "            nn = FeedForward(layers, activation=activation)\n",
    "            # norm inputs\n",
    "            modules = []\n",
    "            if ( 'normIn' in options ):\n",
    "                normIn = options['normIn']\n",
    "                if (normIn != False) and (normIn is not None):\n",
    "                    if normIn == True:\n",
    "                        normIn = 'std'\n",
    "                    mode = normIn\n",
    "                    modules.append(Normalization(n_in,mode=normIn))\n",
    "            modules.append(nn)\n",
    "                       \n",
    "            self.blocks = torch.nn.Sequential(*modules)\n",
    "\n",
    "        self.example_input_array = torch.ones(modules[0].n_in)\n",
    "\n",
    "        # parameters\n",
    "        self.n_in = modules[0].n_in\n",
    "        self.n_out = modules[-1].n_out\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> (torch.tensor):\n",
    "        y = self.blocks(x)\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def loss_function(self, input, target):\n",
    "        # MSE LOSS\n",
    "        loss = (input-target).square().mean()\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, labels = train_batch\n",
    "        y = self(x)\n",
    "        loss = self.loss_function(y,labels)\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, labels = val_batch\n",
    "        y = self(x)\n",
    "        loss = self.loss_function(y,labels)\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "\n",
    "def test_simplecv():\n",
    "    n_in, n_out = 2,1 \n",
    "    layers = [n_in, 5, 10, n_out]\n",
    "\n",
    "    # initialize via dictionary\n",
    "    options= { 'layers' : layers ,\n",
    "               'activation' : 'relu',\n",
    "               'normIn' : True } \n",
    "    model = SimpleCV( options )\n",
    "    print('----------')\n",
    "\n",
    "    # initialize via list of modules\n",
    "    modules = [ Normalization(n_in),\n",
    "                FeedForward(layers, activation='tanh') ]\n",
    "    model = SimpleCV( modules=modules )\n",
    "    print(model)\n",
    "\n",
    "    # create dataset\n",
    "    X = torch.randn((100,2))\n",
    "    y = X.square().sum(1)\n",
    "    dataset = TensorDataset(X,y)\n",
    "    datamodule = TensorDataModule(dataset,lengths=[0.75,0.2,0.05], batch_size=25)\n",
    "    # train model\n",
    "    trainer = pl.Trainer(accelerator='cpu',max_epochs=2,logger=None)\n",
    "    trainer.fit( model, datamodule )\n",
    "    # trace model\n",
    "    traced_model = model.to_torchscript(file_path=\"model_trace.pt\", method='trace', example_inputs=X[0])\n",
    "    model.eval()\n",
    "    assert torch.allclose(model(X),traced_model(X))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_simplecv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cbeac1d7079eaeba64f3210ccac5ee24400128e300a45ae35eee837885b08b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
