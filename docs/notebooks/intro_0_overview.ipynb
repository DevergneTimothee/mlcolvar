{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced sampling and collective variables\n",
    "\n",
    "- cv-based enhanced sampling\n",
    "- meaning of CVs:\n",
    "    1. dimensionality reduction\n",
    "    2. able to distinguish metastable states of interest\n",
    "    3. able to promote the sampling along the minimum free energy pathways\n",
    "- chicken and egg problem\n",
    "- historical pathway: from physics to data-driven\n",
    "    - physical intuition\n",
    "    - linear transformation methods\n",
    "    - non-linear (e.g. nn) cvs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `mlcvs`\n",
    "`mlcvs`, which stands for Machine Learning Collective Variables, is Python library for the construciton of machine learning-based Collective Variables (CVs) for atomistic simulations.\n",
    "\n",
    "The main purposes of `mlcvs` are\n",
    "- Simplify to the bone the use of such CVs for the users.\n",
    "- Provide a flexible framework for further development over previous models.\n",
    "\n",
    "`mlcvs` allows the user to start train and export mlcvs models from scratch with only few lines of code which furthermore do no require any expertise in coding.\n",
    "\n",
    "The library is based on Pytorch and exploits many features of the Pytorch-Lightning package to simplify the overall workflow. \n",
    "The library is thought to be used alongside with PLUMED, thus it is structured to simplify as much as possible the interaction with that in terms of handling of data files and utilization of the mlcvs.\n",
    "\n",
    "<center><img src=\"images/graphical_overview_mlcvs.png\" width=\"800\" /></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mlcvs` workflow\n",
    "The main goal of `mlcvs` is to make the construction of mlcvs as straightforward and accessible as possible for all types of users.\n",
    "\n",
    "In the basic workflow consists of few steps which corresponds to very few lines of code:\n",
    "- Import training data using the functions in `utils`, i.e. PLUMED colvar files or others\n",
    "- Organize the training data into a `DataModule` using the functions in `data`. This allows to expolit best the Lightning features\n",
    "- Initialize the model as one of the CV classes in `cvs`.  \n",
    "- Initialize a `pytorch_lightning.trainer`, this takes care of training, validating, logs and boring stuff :)\n",
    "- Export the trained model with `model.to_torchscript()`\n",
    "- TODO Generate a PLUMED input file \n",
    "- Enjoy the CV in PLUMED with our awesome interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of CVs classes in `mlcvs`\n",
    "\n",
    "The final product of `mlcvs` library are of course the CVs.\n",
    "These are defined as classes which inherit from from a `BaseCV` class and from `pytorch_lightning.module`, which inherits from `torch.nn.module`.\n",
    "\n",
    "The first super class is meant to define a template for all the CVs along with common utility methods and the handling of pre and post processing in the model. \n",
    "\n",
    "The second allows to exploit all the utilites from pytorch lightning.  \n",
    "\n",
    "Each CV is characterized by its specific methods, attributes and properties, which are implemented on top of these two super classes.\n",
    "The structure of CVs in `mlcvs` is thought to be modular, indeed the core of each model is defined as a series of `BLOCKS`, implemented as `torch.nn.module`, that are automatically executed sequentially in a similar fashion to what is done with `torch.nn.sequential`.\n",
    "Each CV then has a `loss_fn` attribute that sets the loss function which has to be minimized for the optimization of the trainable blocks. On the other hand, the optimizer for the training over the trainable weights of the model is set as a property of the model.\n",
    "\n",
    "In additon to the core of the CV class the user can also prepend and append pre and postprocessing models. These are in general thought to be `Transform` object, as they are not trainable, but in principle they could generic `torch.nn.Module`.\n",
    "This possiblity allows to perform the non-trainable preprocessing operations on the dataset only once at the beginning of the training and to include anyways such operations in the final model for exporting, testing etc.\n",
    "Furthermore this allows to perform postprocessing on the outputs of the model and include them after the training is already completed.   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### core\n",
    "Implements building blocks of the mlcvs classes.\n",
    "- **loss** :      Implements loss functions for the training of mlcvs\n",
    "- **nn** :        Implements trainable machine-learning building blocks of the mlcvs classes, conceptually similar to torch.nn \n",
    "- **stats** :     Implements statistical analysis methods (LDA, TICA, PCA..) for the mlcvs classes\n",
    "- **transform** : Implements non-trainable transformations of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cvs\n",
    "Implements ready-to-use mlcvs classes and the `BaseCV` template class.\n",
    "The CVs are divided based on the criterion used for the optimization in: \n",
    "- **unsupervised** :      Only require data about the system (`AutoEncoderCV` and `VariationalAutoEncoderCV`).\n",
    "- **supervised**:         Require either labeled data from the different metastable states of the system (`DeepLDA` and `DeepTDA`) or data and target to be matched (`RegressionCV`)\n",
    "- **timelagged**:         Require time-lagged data from reactive trajectory (`DeepTICA`)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data\n",
    "Implements all the tools used to efficiently handle data in `mlcvs`. The structure is inspired by `pytorch_lightning` with the addition of relying on a dictionary-like handling of the datasets based on keywords indexing for a better ease of use. \n",
    "The key elements are:\n",
    "- **DictionaryDataset**:            A dictionary-like `torch.utils.data.Dataset` that works with tensors and names, i.e data,labels,target,weights etc. \n",
    "- **DictionaryDataModule**:         A `pytorch_lightning.LightningDatamodule` to be initialized from a DictionaryDataset.\n",
    "- **FastDictionaryLoader** :        A DataLoader-like object for sets of tensors. It is adapted to work with dictionaries and to be faster than standard dataloader (see docs).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils\n",
    "Implements miscellanous and transversal tools for a smoother workflow in `mlcvs`. \n",
    "- **io**:            Utils for fast and efficient data import from file, optimized for PLUMED colvar files.  \n",
    "- **fes**:           Function to recover and plot 1D and 2D Free Energy Surface (FES) from biased data. The reweighting function is based on Kernel Density Estimation (KDE) either from `KDEpy` (faster) or `Scipy` (slower).\n",
    "- **timelagged** :   Utils for timelagged datasets.\n",
    "- **plot** :         Utils functions for often-used plots (i.e. `plot_metrics` and `plot_isolines_2D`) and `cm_fessa` and `cortina80` color palettes.\n",
    "- **trainer** :      `pytorch_lihtning.Callback` functions for metrics logging.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test\n",
    "Except for very few simple side functions, all the classes and functions in `mlcvs` are tested to check for potential crashes of the code. The test functions are implemented at the end of each file and simply called here in the `test` folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven collective variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Unsupervised learning\n",
    "- Learn structure from unlabeled data \n",
    "- Only enforced dimensionality reduction task\n",
    "- Data: any"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a) Auto Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Variational Auto Encoder ??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Supervised learning\n",
    "\n",
    "- Learn a regression/classification task\n",
    "- Requires labeled samples (e.g. to which state the configurations belong to)\n",
    "- can be used to enforce requirement that CVs should distinguish metastable states "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) Neural network-based Discriminant Analysis (DeepLDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) Targeted Discriminant Analysis (DeepTDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c) Regression CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Temporal-informed CVs\n",
    "\n",
    "- Learn how system evolve\n",
    "- Can be used to extract slow modes which describe transition from one metastable state to another\n",
    "- BUT require already to have reactive simulations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a) Neural network-based TICA (DeepTICA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b) Time-lagged Auto Encoder (TAE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Multi-task learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a) Autoencoder + TDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cbeac1d7079eaeba64f3210ccac5ee24400128e300a45ae35eee837885b08b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
